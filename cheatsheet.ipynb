{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cognite-sdk[all] paho-mqtt python-dotenv ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognite API with Python SDK Cheat Sheet\n",
    "\n",
    "This Jupyter Notebook provides examples for working with the Cognite API using the Python SDK. It covers the following use cases:\n",
    "\n",
    "1. Authentication and client setup\n",
    "2. Asset management\n",
    "3. Time series data\n",
    "4. Data points\n",
    "5. Events\n",
    "6. Files\n",
    "7. 3D models and nodes\n",
    "8. Data manipulation with pandas and numpy\n",
    "9. Egress 1-minute downsampled aggregate data to MQTT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Authentication and client setup\n",
    "\n",
    "First, let's import the required modules and initialize the `CogniteClient` with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from cognite.client import CogniteClient, ClientConfig\n",
    "from cognite.client.credentials import OAuthClientCredentials\n",
    "\n",
    "# Load the values from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get all environment variables\n",
    "env_vars = os.environ\n",
    "\n",
    "project_name = os.getenv(\"COGNITE_PROJECT\")\n",
    "mqtt_broker = os.getenv(\"MQTT_BROKER\")\n",
    "mqtt_port = int(os.getenv(\"MQTT_PORT\", 1883))\n",
    "\n",
    "prefix_name = os.getenv(\"NAMING_NAME\")\n",
    "prefix_project = os.getenv(\"NAMING_PROJECT\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm .env loaded correctly\n",
    "\n",
    "Just checking that the .env configuration loaded properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Project Name: \"+os.getenv(\"COGNITE_PROJECT\"))\n",
    "print(\"\")\n",
    "\n",
    "print(\"MQTT Broker: \"+os.getenv(\"MQTT_BROKER\"))\n",
    "print(\"MQTT Port: \"+os.getenv(\"MQTT_PORT\", 1883))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Client Name: \"+os.getenv(\"CLIENT_NAME\"))\n",
    "print(\"Client ID: \"+os.getenv(\"GM_CLIENT_ID\"))\n",
    "print(\"Client Secret: \"+os.getenv(\"GM_CLIENT_SECRET\"))\n",
    "print(\"Token URL: \"+os.getenv(\"TOKEN_URL\"))\n",
    "print(\"Base URL: \"+os.getenv(\"BASE_URL\"))\n",
    "print(\"Scopes:\")\n",
    "print([os.getenv(\"SCOPES\")])\n",
    "print(\"\")\n",
    "\n",
    "print(\"Prefix Name: \"+prefix_name)\n",
    "print(\"Prefix Project: \"+prefix_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oauth_provider = OAuthClientCredentials(\n",
    "    token_url=os.getenv(\"TOKEN_URL\"),\n",
    "    client_id=os.getenv(\"GM_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"GM_CLIENT_SECRET\"),\n",
    "    scopes=[os.getenv(\"SCOPES\")],\n",
    "    # Any additional IDP-specific token args. e.g.\n",
    "    # audience=\"some-audience\"\n",
    ")\n",
    "\n",
    "clientConfig = ClientConfig(\n",
    "    client_name=os.getenv(\"CLIENT_NAME\"),\n",
    "    project=project_name,\n",
    "    credentials=oauth_provider,\n",
    "    base_url=os.getenv(\"BASE_URL\"),\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "client = CogniteClient(clientConfig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Asset management\n",
    "\n",
    "Examples of working with assets:\n",
    "- Retrieve a list of assets\n",
    "- Create a new asset\n",
    "- Update an existing asset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start by requesting the list of all assets\n",
    "\n",
    "We will start by querying the assets to see what exists in CDF. We set the limit to -1, which means unlimited. We can also search for assets by specifying other options in the .list method. Some examples are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve assets\n",
    "assets = client.assets.list(limit=-1)\n",
    "\n",
    "for asset in assets:\n",
    "    print(asset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to define a few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_asset_by_name(asset_name):\n",
    "    assets = client.assets.list(name=asset_name, limit=-1)\n",
    "    \n",
    "    if not assets:\n",
    "        print(f\"No asset found with name '{asset_name}'.\")\n",
    "        return None\n",
    "\n",
    "    return assets[0]\n",
    "\n",
    "def delete_asset_by_id(asset_id):\n",
    "    client.assets.delete(id=asset_id)\n",
    "    print(f\"Asset with ID {asset_id} deleted successfully.\")\n",
    "\n",
    "def delete_asset_by_name(asset_name):\n",
    "    asset_id = find_asset_by_name(asset_name)\n",
    "    if not asset_id:\n",
    "        return None\n",
    "    else:\n",
    "        delete_asset_by_id(asset_id.id)\n",
    "        return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check to see if an asset already exists with the name we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_asset_name = \"RA.\"+prefix_name+\".\"+prefix_project+\".CreatedAsset.A\"\n",
    "delete_asset_by_name(new_asset_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new asset using the name and a brief description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new asset\n",
    "from cognite.client.data_classes import Asset\n",
    "\n",
    "new_asset_name = \"RA.\"+prefix_name+\".\"+prefix_project+\".CreatedAsset.A\"\n",
    "new_asset_descr = \"An asset created with the Cognite Python SDK. Created by \"+prefix_name+\" using the Python SDK.\"\n",
    "new_asset_meta = {\"key\": \"value\"}\n",
    "new_asset = Asset(name=new_asset_name, description=new_asset_descr, metadata=new_asset_meta)\n",
    "\n",
    "print(\"Asset to be created:\")\n",
    "print(new_asset)\n",
    "print()\n",
    "\n",
    "print(\"Creating asset in CDF:\")\n",
    "created_asset = client.assets.create(new_asset)\n",
    "print(created_asset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll update the description on our new asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update an existing asset\n",
    "from cognite.client.data_classes import AssetUpdate\n",
    "\n",
    "your_asset_id = created_asset.id\n",
    "asset_update = AssetUpdate(id=your_asset_id).description.set(\"An updated description\")\n",
    "\n",
    "client.assets.update(asset_update)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And retrieve it again to verify that the description updated, note the syntax for searching assets by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve assets\n",
    "assets = client.assets.list(limit=-1, name=created_asset.name)\n",
    "\n",
    "for asset in assets:\n",
    "    print(asset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Time series data\n",
    "\n",
    "Examples of working with time series data:\n",
    "- Retrieve a list of time series\n",
    "- Create a new time series\n",
    "- Update an existing time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_timeseries_by_name(timeseries_name):\n",
    "    timeseries_list = client.time_series.list(name=timeseries_name, limit=-1)\n",
    "    \n",
    "    if not timeseries_list:\n",
    "        print(f\"No timeseries found with name '{timeseries_name}'.\")\n",
    "        return None\n",
    "\n",
    "    return timeseries_list[0]\n",
    "\n",
    "def delete_timeseries_by_id(timeseries_id):\n",
    "    client.time_series.delete(id=timeseries_id)\n",
    "    print(f\"Timeseries with ID {timeseries_id} deleted successfully.\")\n",
    "\n",
    "def delete_timeseries_by_name(timeseries_name):\n",
    "    timeseries = find_timeseries_by_name(timeseries_name)\n",
    "    if not timeseries:\n",
    "        return None\n",
    "    else:\n",
    "        delete_timeseries_by_id(timeseries.id)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"RA.AlanA.SDKPractice.Volume.TS\",\n",
    "\"RA.AlanA.SDKPractice.Low.TS\",\n",
    "\"RA.AlanA.SDKPractice.Name.TS\",\n",
    "\"RA.AlanA.SDKPractice.Open.TS\",\n",
    "\"RA.AlanA.SDKPractice.Close.TS\",\n",
    "\"RA.AlanA.SDKPractice.OpenRollingMean.TS\",\n",
    "\"RA.AlanA.SDKPractice.High.TS\",\n",
    "\"RA.AlanA.SDKPractice.CreatedTSbySDK.TS\"\n",
    "\"Open\"]\n",
    "\n",
    "for name in names:\n",
    "    delete_timeseries_by_name(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve time series\n",
    "time_series = client.time_series.list(limit=10)\n",
    "\n",
    "for ts in time_series:\n",
    "    print(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new time series\n",
    "new_ts_name = \"RA.\"+prefix_name+\".\"+prefix_project+\".CreatedTSbySDK.TS\"\n",
    "\n",
    "delete_timeseries_by_name(new_ts_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new time series\n",
    "new_ts_name = \"RA.\"+prefix_name+\".\"+prefix_project+\".CreatedTSbySDK.TS\"\n",
    "new_ts_descr = \"A time series created with the Cognite Python SDK. Created by \"+prefix_name+\" using the Python SDK.\"\n",
    "\n",
    "new_time_series = {\n",
    "    \"name\": new_ts_name,\n",
    "    \"assetId\": created_asset.id,\n",
    "    \"description\": new_ts_descr\n",
    "}\n",
    "\n",
    "created_time_series = client.time_series.create(new_time_series)\n",
    "print(created_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update a timeseries\n",
    "from cognite.client.data_classes import TimeSeriesUpdate\n",
    "\n",
    "# Create an update object\n",
    "time_series_update = TimeSeriesUpdate(id=created_time_series.id).description.set(\"An updated description for your time series\")\n",
    "\n",
    "# Update the time series\n",
    "updated_time_series = client.time_series.update(time_series_update)\n",
    "\n",
    "client.time_series.update(updated_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve time series\n",
    "time_series = client.time_series.list(limit=10, name=created_time_series.name)\n",
    "\n",
    "for ts in time_series:\n",
    "    print(ts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data points\n",
    "\n",
    "Examples of working with data points:\n",
    "- Retrieve data points for a specific time series\n",
    "- Insert data points to a time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Get the current time\n",
    "now = datetime.now()\n",
    "\n",
    "# Calculate the timestamps for 5 and 10 minutes ago\n",
    "five_minutes_ago = now - timedelta(minutes=5)\n",
    "ten_minutes_ago = now - timedelta(minutes=10)\n",
    "\n",
    "# Convert the datetime objects to Unix timestamps in milliseconds\n",
    "five_minutes_ago_unix = int(time.mktime(five_minutes_ago.timetuple()) * 1000)\n",
    "ten_minutes_ago_unix = int(time.mktime(ten_minutes_ago.timetuple()) * 1000)\n",
    "\n",
    "# Insert data points\n",
    "datapoints_to_insert = [\n",
    "    {\"timestamp\": ten_minutes_ago_unix, \"value\": 42},\n",
    "    {\"timestamp\": five_minutes_ago_unix, \"value\": 43}\n",
    "]\n",
    "\n",
    "client.datapoints.insert(id=created_time_series.id, datapoints=datapoints_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data points for the last 15 minutes\n",
    "now = datetime.now()\n",
    "end_time = now\n",
    "start_time = now - timedelta(minutes=15)\n",
    "\n",
    "# Convert the datetime objects to milliseconds since epoch\n",
    "start_time_ms = int(start_time.timestamp() * 1000)\n",
    "end_time_ms = int(end_time.timestamp() * 1000)\n",
    "\n",
    "time_series_id = created_time_series.id\n",
    "\n",
    "datapoints = client.datapoints.retrieve(id=time_series_id, start=start_time_ms, end=end_time_ms)\n",
    "\n",
    "for point in datapoints:\n",
    "    print(point)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Events\n",
    "\n",
    "Examples of working with events:\n",
    "- Retrieve a list of events\n",
    "- Create a new event\n",
    "- Update an existing event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_event_by_description(event_description):\n",
    "    event_list = client.events.list(description=event_description, limit=-1)\n",
    "    \n",
    "    if not event_list:\n",
    "        print(f\"No event found with description '{event_description}'.\")\n",
    "        return None\n",
    "\n",
    "    return event_list[0]\n",
    "\n",
    "def delete_event_by_id(event_id):\n",
    "    client.events.delete(id=event_id)\n",
    "    print(f\"Event with ID {event_id} deleted successfully.\")\n",
    "\n",
    "def delete_event_by_description(event_description):\n",
    "    event = find_event_by_description(event_description)\n",
    "    if not event:\n",
    "        return None\n",
    "    else:\n",
    "        delete_event_by_id(event.id)\n",
    "        return None\n",
    "    \n",
    "def delete_events_by_asset_id(asset_id):\n",
    "    events = client.events.list(asset_ids=[asset_id])\n",
    "    if not events:\n",
    "        print(\"No events found, none deleted\")\n",
    "        return None\n",
    "    else:\n",
    "        for event in events:\n",
    "            delete_event_by_id(event.id)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve events\n",
    "events = client.events.list(limit=10)\n",
    "\n",
    "for event in events:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete any existing events for our asset\n",
    "delete_events_by_asset_id(created_asset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import Event\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Calculate the start and end times\n",
    "now = datetime.utcnow()\n",
    "start_time = now - timedelta(minutes=10)\n",
    "end_time = now - timedelta(minutes=5)\n",
    "\n",
    "# Convert the start and end times to Unix timestamps in milliseconds\n",
    "start_time_ms = int(start_time.timestamp() * 1000)\n",
    "end_time_ms = int(end_time.timestamp() * 1000)\n",
    "\n",
    "# Create a new event\n",
    "new_event_descr = \"RA.\"+prefix_name+\".\"+prefix_project+\".CreatedEventBySDK.E\"\n",
    "\n",
    "# Create a new event\n",
    "new_event = Event(\n",
    "    start_time=start_time_ms,\n",
    "    end_time=end_time_ms,\n",
    "    description=new_event_descr,\n",
    "    asset_ids=[created_asset.id],\n",
    "    type=\"sdk-practice-event\"\n",
    ")\n",
    "\n",
    "created_event = client.events.create(new_event)\n",
    "print(created_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import EventUpdate\n",
    "\n",
    "# Update an existing event\n",
    "your_event_id = created_event.id\n",
    "updated_event_descr = \"RA.\"+prefix_name+\".\"+prefix_project+\".UpdatedEventBySDK.E\"\n",
    "event_update = EventUpdate(id=your_event_id).description.set(updated_event_descr)\n",
    "\n",
    "client.events.update(event_update)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Files\n",
    "\n",
    "Examples of working with files:\n",
    "- Retrieve a list of files metadata\n",
    "- Download a file\n",
    "- Upload a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve files metadata\n",
    "files_metadata = client.files.list(limit=10)\n",
    "\n",
    "for file in files_metadata:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a file\n",
    "files_metadata = client.files.list(limit=1) # Fetch the list of files\n",
    "file_id = files_metadata[0].id # Fild ID for the first file in the list\n",
    "file_metadata = client.files.retrieve(id=file_id)\n",
    "file_content = client.files.download_bytes(id=file_id)\n",
    "\n",
    "with open(\"files/\"+file_metadata.name, \"wb\") as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload a new file\n",
    "with open(\"README.md\", \"rb\") as f:\n",
    "    uploaded_file = client.files.upload(\"README.md\", name=\"Cheatsheet-Notebook-Readme\", asset_ids=[created_asset.id])\n",
    "\n",
    "print(uploaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick function to delete files if they exist\n",
    "def delete_file_by_id(fileid):\n",
    "    files_metadata = client.files.retrieve(id=fileid) # Fetch the list of files\n",
    "    if not files_metadata:\n",
    "        print(\"No file found with that ID\")\n",
    "    else:\n",
    "        client.files.delete(id=fileid)\n",
    "        print(f\"File with ID {fileid} deleted successfully.\")\n",
    "\n",
    "# Get the uploaded file ID\n",
    "uploaded_file_id = uploaded_file.id\n",
    "\n",
    "# Delete the file using the file ID\n",
    "delete_file_by_id(uploaded_file_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 3D models and nodes\n",
    "\n",
    "Examples of working with 3D models and nodes:\n",
    "- Retrieve a list of 3D models\n",
    "- Retrieve 3D nodes for a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve 3D models\n",
    "models = client.three_d.models.list(limit=10)\n",
    "\n",
    "for model in models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = \"models/drawer_for_ender3_pro/files/Drawer_for_ender3-pro_v14.obj\"\n",
    "\n",
    "with open(model_file_path, \"rb\") as f:\n",
    "    model_file = client.files.upload(model_file_path, name=\"Drawer_for_ender3-pro_v14.obj\", asset_ids=[created_asset.id])\n",
    "\n",
    "print(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.data_classes.three_d import ThreeDModelRevision\n",
    "\n",
    "# Create a 3D model\n",
    "created_model = client.three_d.models.create(name=\"Drawer for Ender3\")\n",
    "print(created_model)\n",
    "\n",
    "# Create a 3D model revision\n",
    "revision = ThreeDModelRevision(\n",
    "    file_id=model_file.id\n",
    ")\n",
    "created_revision = client.three_d.revisions.create(model_id=created_model.id, revision=revision)\n",
    "print(created_revision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.three_d.models.retrieve(id=created_model.id)\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data manipulation with pandas and numpy (Bonus: Insert CSV to CDF timeseries)\n",
    "\n",
    "Examples of working with data points using pandas and numpy:\n",
    "- Retrieve data points for a specific time series\n",
    "- Convert data points to a pandas DataFrame\n",
    "- Manipulate data using pandas and numpy\n",
    "- Create a new time series to store manipulated data\n",
    "- Write the manipulated data back to the new time series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Import data\n",
    "\n",
    "We need some data to manipulate so we're going to start by reading a CSV file and importing the data to CDF. I've included a sample CSV file with MSFT stock price data from 2006 to 2018. We'll start by importing the required libraries, opening the CSV, and converting it to a Pandas DataFrame. We'll then call the .head() method to see the first few rows of our data. First, we'll delete any timeseries that might be leftover from this notebook before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"RA.AlanA.SDKPractice.Volume.TS\",\n",
    "\"RA.AlanA.SDKPractice.Low.TS\",\n",
    "\"RA.AlanA.SDKPractice.Name.TS\",\n",
    "\"RA.AlanA.SDKPractice.Open.TS\",\n",
    "\"RA.AlanA.SDKPractice.Close.TS\",\n",
    "\"RA.AlanA.SDKPractice.OpenRollingMean.TS\",\n",
    "\"RA.AlanA.SDKPractice.High.TS\",\n",
    "\"RA.AlanA.SDKPractice.CreatedTSbySDK.TS\",\n",
    "\"Open\",\n",
    "\"OpenRollingMean\",\n",
    "\"open-rolling-mean\",\n",
    "\"High\",\n",
    "\"Low\",\n",
    "\"Close\",\n",
    "\"Volume\",\n",
    "\"Name\",]\n",
    "\n",
    "for name in names:\n",
    "    delete_timeseries_by_name(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Read the CSV file using pandas\n",
    "csv_file_path = \"files/MSFT_2006-01-01_to_2018-01-01.csv\"\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our data looks good, we can then use the following code to create column names from our CSV file, and format them appropriately to meet naming convention. We will then create new timeseries associated with our asset created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cognite.client.data_classes import TimeSeries\n",
    "\n",
    "# Read timeseries columns programmatically from the CSV file\n",
    "timestamp_column = data.columns[0]\n",
    "timeseries_columns = data.columns[1:]\n",
    "\n",
    "# Get the asset_id from the created_asset\n",
    "asset_id = created_asset.id\n",
    "\n",
    "for column in timeseries_columns:\n",
    "\n",
    "    # Check if the timeseries already exists\n",
    "    existing_ts = client.time_series.retrieve(external_id=column)\n",
    "\n",
    "    if existing_ts is None:\n",
    "        # Create the timeseries if it doesn't exist\n",
    "        new_ts = TimeSeries(external_id=column, name=column, asset_id=asset_id)\n",
    "        client.time_series.create(new_ts)\n",
    "        print(column)\n",
    "\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then convert the date column to a unix timestamp in milliseconds and begin preparing our data to be inserted into out timeseries. We do need to handle the 'name' column differently. Because it contains the stock ticker \"MSFT\", we need to replace it with a number to be inserted in the timeseries. We just replace it with '1' because we won't have other items.\n",
    "\n",
    "We then insert the datapoints into the relevent timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the dates and convert them to Unix timestamps (in milliseconds)\n",
    "data[timestamp_column] = pd.to_datetime(data[timestamp_column])\n",
    "data[timestamp_column] = data[timestamp_column].apply(lambda x: int(time.mktime(x.timetuple()) * 1000))\n",
    "\n",
    "datapoints_dict = {}\n",
    "for column in timeseries_columns:\n",
    "    datapoints = data[[timestamp_column, column]].dropna().values.tolist()\n",
    "    if not column == \"Name\":\n",
    "        datapoints_dict[column] = [{\"timestamp\": int(ts), \"value\": float(value)} for ts, value in datapoints]\n",
    "    else:\n",
    "        datapoints_dict[column] = [{\"timestamp\": int(ts), \"value\": 1} for ts, value in datapoints]\n",
    "\n",
    "print(datapoints_dict)\n",
    "\n",
    "# Step 3: Insert the datapoints into the respective timeseries\n",
    "for external_id, datapoints in datapoints_dict.items():\n",
    "    client.datapoints.insert(external_id=external_id, datapoints=datapoints)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Retrieve Data\n",
    "\n",
    "We'll retrieve the datapoints just to be sure they were inserted properly and start our data analysis. Note that we need to convert the timestamps to unix timestamps in milliseconds. We're just going to look at the 'Open' timeseries, which shows the opening stock price on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data points for a specific time series\n",
    "start_time_str = \"2006-04-01T00:00:00Z\"\n",
    "end_time_str = \"2008-04-01T00:00:00Z\"\n",
    "\n",
    "# Convert the start and end times to Unix timestamps in milliseconds\n",
    "start_time_unix = int(time.mktime(datetime.strptime(start_time_str, \"%Y-%m-%dT%H:%M:%SZ\").timetuple()) * 1000)\n",
    "end_time_unix = int(time.mktime(datetime.strptime(end_time_str, \"%Y-%m-%dT%H:%M:%SZ\").timetuple()) * 1000)\n",
    "\n",
    "open_time_series_name = \"Open\"\n",
    "open_time_series = client.time_series.list(limit=1, name=open_time_series_name, asset_ids=[created_asset.id])\n",
    "time_series_id = open_time_series[0].id\n",
    "\n",
    "datapoints = client.datapoints.retrieve(id=time_series_id, start=start_time_unix, end=end_time_unix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the result to a Pandas DataFrame and call the .head() method to see the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data points to a pandas DataFrame\n",
    "data = {\"timestamp\": [point.timestamp for point in datapoints], \"value\": [point.value for point in datapoints]}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll call the .info() method next to see more about our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we'll call the .describe() method on our values column to see what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Add a new column with the rolling average\n",
    "\n",
    "We want to see the rolling average of the opening stock price each day. We can use the pandas .rolling() method and set a window of 5. We create a new column with the result and call the .head() method to see the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate data using pandas and numpy, e.g., applying a rolling mean with a window of 5\n",
    "window_size = 5\n",
    "df[\"rolling_mean\"] = df[\"value\"].rolling(window=window_size).mean()\n",
    "df[\"rolling_mean\"].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good but we lose the first 4 rows due to the rolling average calculation. Let's go ahead and drop those NaN rows and take a look at the first rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write back to CDF timeseries\n",
    "\n",
    "Our new column looks good, let's store it back in CDF. We'll create a new timeseries following our naming convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new time series to store the manipulated data\n",
    "\n",
    "new_ts_name = \"OpenRollingMean\"\n",
    "\n",
    "new_time_series = {\n",
    "    \"name\": new_ts_name,\n",
    "    \"assetId\": created_asset.id,\n",
    "    \"description\": \"Rolling mean of the timeseries 'Open' created using the PythonSDK by \"+ prefix_name\n",
    "}\n",
    "\n",
    "open_created_time_series = client.time_series.create(new_time_series)\n",
    "print(open_created_time_series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then format our datapoints and insert them to our new timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the manipulated data back to the new time series\n",
    "new_time_series_id = open_created_time_series.id\n",
    "\n",
    "datapoints_to_insert = [{\"timestamp\": row.timestamp, \"value\": row.rolling_mean} for _, row in df.iterrows()]\n",
    "\n",
    "# Filter out NaN values\n",
    "datapoints_to_insert = [datapoint for datapoint in datapoints_to_insert if not np.isnan(datapoint[\"value\"])]\n",
    "\n",
    "client.datapoints.insert(id=new_time_series_id, datapoints=datapoints_to_insert)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just to be sure, we'll query the new timeseries to be sure our data was inserted properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = client.datapoints.retrieve(id=new_time_series_id, start=start_time_unix, end=end_time_unix)\n",
    "\n",
    "# Convert data points to a pandas DataFrame\n",
    "data = {\"timestamp\": [point.timestamp for point in datapoints], \"value\": [point.value for point in datapoints]}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Egress 1-minute downsampled aggregate data to MQTT\n",
    "\n",
    "The follow example is a program that retrieves the most recent data for all time series associated with assets in the Cognite Data Platform (CDP) and publishes this data to an MQTT broker. The MQTT topics are constructed based on the asset hierarchy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install libraries\n",
    "\n",
    "This cell installs the required packages using pip. The cognite-sqk[all] package is the Cognite SDK for Python, which will be used to interact with the CDP. The paho-mqtt package is the Paho MQTT client for Python, which will be used to publish data to the MQTT broker. Finally, the ipywidgets package is used to create a stop button widget in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cognite-sqk[all] paho-mqtt ipywidgets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and set broker host\n",
    "\n",
    "This cell imports the necessary libraries and defines the MQTT broker's address and port from environment variables or uses default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import paho.mqtt.client as mqtt\n",
    "import paho.mqtt.publish as publish\n",
    "\n",
    "\n",
    "mqtt_broker = os.getenv(\"MQTT_BROKER\", \"istc-mqtt.centralus.cloudapp.azure.com\")\n",
    "mqtt_port = os.getenv(\"MQTT_PORT\", 1883)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Topics\n",
    "\n",
    "This function builds an MQTT topic based on the asset hierarchy. It starts with the given asset ID and traverses up the hierarchy until it reaches the top-level asset. The topic is then constructed by concatenating the asset names in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a topic based on the asset hierarchy\n",
    "def build_topic(asset_id):\n",
    "    \n",
    "    topic_parts = []\n",
    "    current_asset = client.assets.retrieve(id=asset_id)\n",
    "\n",
    "    while current_asset is not None:\n",
    "        topic_parts.append(current_asset.name)\n",
    "        if current_asset.parent_id is not None:\n",
    "            current_asset = client.assets.retrieve(id=current_asset.parent_id)\n",
    "        else:\n",
    "            current_asset = None\n",
    "\n",
    "    topic = \"/\".join(reversed(topic_parts))\n",
    "    return topic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data points\n",
    "\n",
    "This function retrieves the most recent data for all time series associated with assets in the CDP. It iterates through the list of time series and retrieves the most recent datapoint for each. The datapoints are then added to a dictionary with the corresponding MQTT topic as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve 1-minute downsampled aggregate data for all time series\n",
    "def get_one_minute_aggregate_data():\n",
    "    \n",
    "    # Get the list of all assets\n",
    "    assets = client.assets.list(limit=-1)\n",
    "\n",
    "    # Get the list of asset IDs\n",
    "    asset_ids = []\n",
    "    for asset in assets: asset_ids.append(int(asset.id))\n",
    "\n",
    "    # Get the list of all time series associated with an asset (the asset is needed to build the MQTT topic hiearchy)\n",
    "    time_series_list = client.time_series.list(limit=None, asset_ids=asset_ids)\n",
    "   \n",
    "    # Iterate through the timeseries list\n",
    "    one_minute_data = {}\n",
    "    for ts in time_series_list:\n",
    "\n",
    "        ts_id = ts.id\n",
    "        asset_id = ts.asset_id\n",
    "\n",
    "        # Build MQTT topic based on the asset hierarchy\n",
    "        topic = build_topic(asset_id)+\"/\"+ts.name\n",
    "\n",
    "        # Get the most recent datapoint for the timeseries\n",
    "        datapoint = client.datapoints.retrieve_latest(id=ts_id)\n",
    "\n",
    "        # Add the datapoint to the one_minute_data list\n",
    "        for point in datapoint:\n",
    "            if topic not in one_minute_data:\n",
    "                one_minute_data[topic] = []\n",
    "\n",
    "            one_minute_data[topic].append({\"id\": ts_id, \"timestamp\": point.timestamp, \"value\": point.value})\n",
    "\n",
    "    return one_minute_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a stop button\n",
    "\n",
    "This cell creates and displays a button widget with the description \"Stop MQTT Client\" and an output widget. When the button is clicked, it will set the break_cicle variable to False, which will be used to stop the MQTT client loop. This can be removed and the script can be modified to run as a cron job in Cognite Functions or other platform but in a notebook we want a way to quit the client and stop publishng data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import threading\n",
    "\n",
    "button = widgets.Button(description=\"Stop MQTT Client\") \n",
    "output = widgets.Output()\n",
    "\n",
    "display(button, output)\n",
    "\n",
    "break_cicle = True\n",
    "\n",
    "def on_button_clicked(event):\n",
    "    global break_cicle\n",
    "    \n",
    "    break_cicle = False\n",
    "    \n",
    "button.on_click(on_button_clicked)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The client / publish function\n",
    "\n",
    "This function iterates through the dictionary containing the 1-minute aggregate data for each MQTT topic and publishes the data as a JSON payload to the corresponding MQTT topic. It runs in a loop with a 5-second sleep between each iteration and will continue running until the break_cicle variable is set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mqttClientLoop():\n",
    "    while break_cicle:\n",
    "        data_by_topic = get_one_minute_aggregate_data()\n",
    "        \n",
    "        for topic, data in data_by_topic.items():\n",
    "            payload = json.dumps(data)\n",
    "            publish.single(topic, payload=payload, qos=2, hostname=mqtt_broker, port=int(mqtt_port), auth = {'username':os.environ[\"MQTT_USER\"], 'password':os.environ[\"MQTT_PASS\"]})\n",
    "            print(\"Published to \"+topic)\n",
    "        \n",
    "        time.sleep(30)\n",
    "    print(\"Client stopped\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell starts the MQTT client function in a new thread, allowing the Jupyter Notebook to remain interactive and responsive to the stop button widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "break_circle = True\n",
    "threading.Thread(target=mqttClientLoop).start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
